{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMNEY8cI8jAqOqpQUITJ16q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fjavidcr/test-gen-ai-vertex/blob/master/Vertex_AI_GenAi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Instala el SDK de Vertex AI SDK: Abre la ventana de terminal y, luego, ingresa el siguiente comando. TambiÃ©n puedes instalar en un entorno virtual (https://googleapis.dev/python/aiplatform/latest/index.html) .\n",
        "\n",
        ">!pip install --upgrade google-cloud-aiplatform\n",
        "\n"
      ],
      "metadata": {
        "id": "i8gEJFsBr0Th"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbCsGLGYrqKI"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "from vertexai.language_models import ChatModel, InputOutputTextPair\n",
        "\n",
        "vertexai.init(project=\"test-vertex-ai-gemini\", location=\"us-central1\")\n",
        "chat_model = ChatModel.from_pretrained(\"chat-bison\")\n",
        "parameters = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"max_output_tokens\": 1024,\n",
        "    \"temperature\": 0.9,\n",
        "    \"top_p\": 1\n",
        "},\n",
        "safety_settings={\n",
        "          generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "          generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "          generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "          generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
        "    }\n",
        "chat = chat_model.start_chat(\n",
        "    context=\"\"\"You are a customer service chatbot\n",
        "for Lola\\'s Lollipops. You only\n",
        "answer customer questions about\n",
        "Lola\\'s Lollipops and its products.\n",
        "\n",
        "Highlight our newest product, the\n",
        "orange creamsicle lollipop with a\n",
        "creamy vanilla center.\"\"\",\n",
        "    examples=[\n",
        "        InputOutputTextPair(\n",
        "            input_text=\"\"\"Do you sell soft drinks?\"\"\",\n",
        "            output_text=\"\"\"Sorry. We only sell candy.\"\"\"\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "response = chat.send_message(\"\"\"What\\'s the weather like?\"\"\", **parameters)\n",
        "print(f\"Response from Model: {response.text}\")\n",
        "response = chat.send_message(\"\"\"What\\'s the weather like?\"\"\", **parameters)\n",
        "print(f\"Response from Model: {response.text}\")\n",
        "response = chat.send_message(\"\"\"What types of sodas do you have?\"\"\", **parameters)\n",
        "print(f\"Response from Model: {response.text}\")\n",
        "response = chat.send_message(\"\"\"What\\'s the weather like?\"\"\", **parameters)\n",
        "print(f\"Response from Model: {response.text}\")\n",
        "response = chat.send_message(\"\"\"What types of sodas do you have?\"\"\", **parameters)\n",
        "print(f\"Response from Model: {response.text}\")\n",
        "response = chat.send_message(\"\"\"Tell me about your lollipops\"\"\", **parameters)\n",
        "print(f\"Response from Model: {response.text}\")"
      ]
    }
  ]
}